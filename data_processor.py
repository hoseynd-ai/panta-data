"""
Ø³ÛŒØ³ØªÙ… Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ú©Ø³Ù„
Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡: hoseynd-ai
ØªØ§Ø±ÛŒØ®: 2025-01-23 (Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ - Ø¨Ø¯ÙˆÙ† Ø®Ø·Ø§)
"""

import pandas as pd
import re
from typing import List, Tuple, Any, Dict, Optional
from rapidfuzz import fuzz, process
import datetime
from dataclasses import dataclass, asdict
from enum import Enum
import json
from pathlib import Path


# ==================== Enums ====================
class SearchMode(Enum):
    """Ø­Ø§Ù„Øªâ€ŒÙ‡Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ"""
    EXACT = "exact"
    FUZZY = "fuzzy"
    PARTIAL = "partial"
    AUTO = "auto"


# ==================== Data Classes ====================
@dataclass
class SearchResult:
    """Ù†ØªÛŒØ¬Ù‡ Ø¬Ø³ØªØ¬Ùˆ"""
    customer_name: str
    match_score: float
    total_purchases: int
    formal_purchases: int
    informal_purchases: int
    years_active: List[int]
    months_active: List[int]
    mobile_numbers: List[str]
    phone_numbers: List[str]
    addresses: List[str]
    products: List[str]
    total_products: int
    
    def to_dict(self):
        return asdict(self)


class DataProcessor:
    """Ú©Ù„Ø§Ø³ Ø§ØµÙ„ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡"""
    
    def __init__(self, excel_file: str = "temp_excel_files_by_year_panta-new.xlsx"):
        self.excel_file = excel_file
        self.df = None
        self.processed_data = None
        
        # Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ
        self.data_dir = Path("crm_data")
        self.data_dir.mkdir(exist_ok=True)
        
        # Ú©Ø´ Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø³Ø±ÛŒØ¹â€ŒØªØ±
        self.customer_index = {}
    
    # ==================== Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ====================
    
    def load_data(self, file_path: str = None) -> pd.DataFrame:
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„"""
        try:
            file_path = file_path or self.excel_file
            
            xls = pd.ExcelFile(file_path)
            frames = []
            
            for sheet_name in xls.sheet_names:
                df_sheet = pd.read_excel(file_path, sheet_name=sheet_name)
                df_sheet['sheet_name'] = sheet_name
                frames.append(df_sheet)
            
            self.df = pd.concat(frames, ignore_index=True)
            self.df.columns = self.df.columns.str.strip()
            
            return self.df
            
        except Exception as e:
            raise Exception(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„: {e}")
    
    # ==================== Ù¾Ø±Ø¯Ø§Ø²Ø´ ====================
    
    def process_data(self, df: pd.DataFrame = None) -> pd.DataFrame:
        """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡"""
        if df is not None:
            self.df = df
        
        if self.df is None:
            raise Exception("Ø§Ø¨ØªØ¯Ø§ ÙØ§ÛŒÙ„ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯.")
        
        out = self.df.copy()
        
        # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù†Ø§Ù… Ù…Ø´ØªØ±ÛŒ
        out['customer_name'] = out['customer name'].astype(str).str.strip()
        out['customer_name_normalized'] = out['customer_name'].apply(self._normalize_text)
        
        # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø³Ø§Ù„ Ùˆ Ù…Ø§Ù‡
        out['year'] = pd.to_numeric(out['year'], errors='coerce')
        out['month'] = pd.to_numeric(out['month'], errors='coerce')
        
        # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÙØ§Ø±Ø´
        out['state_original'] = out['state'].astype(str).str.strip()
        out['state_normalized'] = out['state_original'].apply(self._normalize_state)
        
        # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø¢Ø¯Ø±Ø³
        out['address'] = out['address'].astype(str).str.strip()
        
        # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ ØªÙ„ÙÙ†â€ŒÙ‡Ø§
        out['mobile'] = out['Ø´Ù…Ø§Ø±Ù‡ Ù…ÙˆØ¨Ø§ÛŒÙ„'].astype(str).apply(self._clean_phone)
        out['phone'] = out['Ø´Ù…Ø§Ø±Ù‡ Ø«Ø§Ø¨Øª'].astype(str).apply(self._clean_phone)
        
        # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª (Ø¨Ø§ Ú©Ø§Ù…Ø§ Ø¬Ø¯Ø§ Ø´Ø¯Ù‡)
        out['products_list'] = out['Ù†Ø§Ù… Ù…Ø­ØµÙˆÙ„'].apply(self._parse_products)
        out['products_list_normalized'] = out['products_list'].apply(
            lambda x: [self._normalize_product_name(p) for p in x]
        )
        out['product_count'] = out['products_list'].apply(len)
        
        # Ø­Ø°Ù Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù„ÛŒ
        out = out.dropna(subset=['customer_name'])
        out = out[out['customer_name'] != 'nan']
        out = out[out['customer_name'] != '']
        
        self.processed_data = out
        self._build_customer_index()
        
        return out
    
    # ==================== ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ ====================
    
    @staticmethod
    def _normalize_text(text: str) -> str:
        """Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ"""
        if not isinstance(text, str) or text == 'nan':
            return ""
        
        text = text.replace("ÙŠ", "ÛŒ").replace("Ùƒ", "Ú©")
        text = text.replace("\u200c", " ")
        text = re.sub(r'\s+', ' ', text)
        
        return text.strip().lower()
    
    @staticmethod
    def _normalize_state(state: str) -> str:
        """Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÙØ§Ø±Ø´"""
        if not isinstance(state, str) or state == 'nan' or state.strip() == '':
            return "Ù†Ø§Ù…Ø´Ø®Øµ"
        
        s = state.strip()
        s = s.replace("ÙŠ", "ÛŒ").replace("Ùƒ", "Ú©")
        s_no_space = s.replace(" ", "").replace("\u200c", "").replace("\t", "").replace("\n", "").replace("\r", "")
        s_lower = s_no_space.lower()
        
        formal_keywords = ['Ø±Ø³Ù…ÛŒ', 'Ø±Ø³Ù…ÙŠ', 'formal', 'official', 'ÙØ§Ú©ØªÙˆØ±', 'invoice']
        informal_keywords = ['ØºÛŒØ±Ø±Ø³Ù…ÛŒ', 'ØºÛŒØ±Ø±Ø³Ù…ÙŠ', 'ØºÛŒØ±Ù‘Ø³Ù…ÛŒ', 'ØºÛŒØ±Ø³Ù…ÛŒ', 'informal', 'unofficial', 'Ù¾ÛŒØ´ÙØ§Ú©ØªÙˆØ±', 'Ù¾ÛŒØ´â€ŒÙØ§Ú©ØªÙˆØ±', 'proforma']
        
        formal_normalized = [k.replace(" ", "").replace("\u200c", "").lower() for k in formal_keywords]
        informal_normalized = [k.replace(" ", "").replace("\u200c", "").lower() for k in informal_keywords]
        
        for keyword in informal_normalized:
            if keyword in s_lower:
                return "ØºÛŒØ±Ø±Ø³Ù…ÛŒ"
        
        for keyword in formal_normalized:
            if keyword in s_lower:
                return "Ø±Ø³Ù…ÛŒ"
        
        return s if s else "Ù†Ø§Ù…Ø´Ø®Øµ"
    
    @staticmethod
    def _normalize_product_name(product: str) -> str:
        """
        Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù†Ø§Ù… Ù…Ø­ØµÙˆÙ„Ø§Øª
        
        ØªØ¨Ø¯ÛŒÙ„ ØªÙ…Ø§Ù… Ø­Ø§Ù„Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù ÛŒÚ© Ù…Ø­ØµÙˆÙ„ Ø¨Ù‡ ÛŒÚ© Ù†Ø§Ù… Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
        
        Ù…Ø«Ø§Ù„:
            "Panflow 110" â†’ "panflow110"
            "P.N-Coat" â†’ "pncoat"
            "PNR 2" â†’ "pnr2"
        """
        if not isinstance(product, str) or product == 'nan' or product.strip() == '':
            return ""
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø­Ø±ÙˆÙ Ú©ÙˆÚ†Ú©
        normalized = product.lower()
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø­Ø±ÙˆÙ Ø¹Ø±Ø¨ÛŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ
        normalized = normalized.replace("ÙŠ", "ÛŒ").replace("Ùƒ", "Ú©")
        
        # Ø­Ø°Ù ØªÙ…Ø§Ù… Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ ØºÛŒØ±Ø­Ø±Ù Ùˆ ØºÛŒØ±Ø¹Ø¯Ø¯ (ÙÙ‚Ø· Ø­Ø±ÙˆÙ Ùˆ Ø§Ø¹Ø¯Ø§Ø¯ Ø¨Ø§Ù‚ÛŒ Ø¨Ù…Ø§Ù†Ø¯)
        normalized = re.sub(r'[^a-zA-Z0-9Ø¢-ÛŒ]', '', normalized)
        
        # Ø­Ø°Ù ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
        normalized = normalized.strip()
        
        return normalized
    
    @staticmethod
    def _clean_phone(phone: str) -> str:
        """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø´Ù…Ø§Ø±Ù‡ ØªÙ„ÙÙ†"""
        if not isinstance(phone, str) or phone == 'nan':
            return ""
        
        phone = re.sub(r'[^\d]', '', phone)
        
        if phone.startswith('98') and len(phone) >= 10:
            phone = '0' + phone[2:]
        
        return phone
    
    def _parse_products(self, products_str: str) -> List[str]:
        """ØªØ¬Ø²ÛŒÙ‡ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø§ Ú©Ø§Ù…Ø§"""
        if not isinstance(products_str, str) or products_str == 'nan':
            return []
        
        products = re.split(r'[,ØŒ]', products_str)
        products = [p.strip() for p in products if p.strip()]
        
        return products
    
    # ==================== Ø§ÛŒÙ†Ø¯Ú©Ø³ ====================
    
    def _build_customer_index(self):
        """Ø³Ø§Ø®Øª Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø³Ø±ÛŒØ¹"""
        if self.processed_data is None:
            return
        
        self.customer_index = {}
        
        for customer_name in self.processed_data['customer_name'].unique():
            customer_data = self.processed_data[
                self.processed_data['customer_name'] == customer_name
            ]
            
            years = sorted(customer_data['year'].dropna().unique().tolist())
            months = sorted(customer_data['month'].dropna().unique().tolist())
            
            formal_count = len(customer_data[customer_data['state_normalized'] == 'Ø±Ø³Ù…ÛŒ'])
            informal_count = len(customer_data[customer_data['state_normalized'] == 'ØºÛŒØ±Ø±Ø³Ù…ÛŒ'])
            
            mobiles = customer_data['mobile'].unique().tolist()
            phones = customer_data['phone'].unique().tolist()
            addresses = customer_data['address'].unique().tolist()
            
            all_products = []
            for products_list in customer_data['products_list']:
                all_products.extend(products_list)
            all_products = list(set(all_products))
            
            normalized_name = self._normalize_text(customer_name)
            keywords = normalized_name.split()
            
            self.customer_index[customer_name] = {
                'normalized_name': normalized_name,
                'keywords': keywords,
                'total_purchases': len(customer_data),
                'formal_purchases': formal_count,
                'informal_purchases': informal_count,
                'years_active': years,
                'months_active': months,
                'mobile_numbers': [m for m in mobiles if m],
                'phone_numbers': [p for p in phones if p],
                'addresses': [a for a in addresses if a and a != 'nan'],
                'products': all_products,
                'total_products': len(all_products)
            }
    
    # ==================== Ø¬Ø³ØªØ¬Ùˆ ====================
    
    def search_customer(
        self,
        query: str,
        mode: SearchMode = SearchMode.AUTO,
        min_score: int = 60
    ) -> List[SearchResult]:
        """Ø¬Ø³ØªØ¬ÙˆÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…Ø´ØªØ±ÛŒ"""
        if not query.strip():
            return []
        
        query_normalized = self._normalize_text(query)
        query_keywords = query_normalized.split()
        
        results = []
        
        for customer_name, info in self.customer_index.items():
            score = 0
            
            if mode == SearchMode.EXACT:
                if info['normalized_name'] == query_normalized:
                    score = 100
            
            elif mode == SearchMode.PARTIAL:
                matches = 0
                for q_word in query_keywords:
                    if any(q_word in keyword for keyword in info['keywords']):
                        matches += 1
                
                if matches > 0:
                    score = (matches / len(query_keywords)) * 100
            
            elif mode == SearchMode.FUZZY:
                score = fuzz.token_set_ratio(query_normalized, info['normalized_name'])
            
            else:  # AUTO
                if info['normalized_name'] == query_normalized:
                    score = 100
                elif query_normalized in info['normalized_name']:
                    score = 95
                else:
                    matches = 0
                    for q_word in query_keywords:
                        for keyword in info['keywords']:
                            if q_word in keyword:
                                matches += 1
                                break
                            elif fuzz.ratio(q_word, keyword) > 85:
                                matches += 0.8
                                break
                    
                    if matches > 0:
                        score = (matches / len(query_keywords)) * 90
                    else:
                        score = fuzz.token_set_ratio(query_normalized, info['normalized_name']) * 0.8
            
            if score >= min_score:
                results.append(SearchResult(
                    customer_name=customer_name,
                    match_score=round(score, 2),
                    total_purchases=info['total_purchases'],
                    formal_purchases=info['formal_purchases'],
                    informal_purchases=info['informal_purchases'],
                    years_active=info['years_active'],
                    months_active=info['months_active'],
                    mobile_numbers=info['mobile_numbers'],
                    phone_numbers=info['phone_numbers'],
                    addresses=info['addresses'],
                    products=info['products'],
                    total_products=info['total_products']
                ))
        
        results.sort(key=lambda x: x.match_score, reverse=True)
        
        return results
    
    # ==================== ØªØ­Ù„ÛŒÙ„ ====================
    
    def get_yearly_stats(self) -> pd.DataFrame:
        """Ø¢Ù…Ø§Ø± Ø³Ø§Ù„Ø§Ù†Ù‡"""
        if self.processed_data is None:
            return pd.DataFrame()
        
        stats = self.processed_data.groupby('year').agg({
            'customer_name': 'nunique',
            'mobile': 'count',
            'product_count': 'sum'
        }).reset_index()
        
        stats.columns = ['Ø³Ø§Ù„', 'ØªØ¹Ø¯Ø§Ø¯_Ù…Ø´ØªØ±ÛŒ', 'ØªØ¹Ø¯Ø§Ø¯_Ø³ÙØ§Ø±Ø´', 'ØªØ¹Ø¯Ø§Ø¯_Ù…Ø­ØµÙˆÙ„']
        
        formal = self.processed_data[
            self.processed_data['state_normalized'] == 'Ø±Ø³Ù…ÛŒ'
        ].groupby('year').size().reset_index(name='Ø³ÙØ§Ø±Ø´_Ø±Ø³Ù…ÛŒ')
        
        informal = self.processed_data[
            self.processed_data['state_normalized'] == 'ØºÛŒØ±Ø±Ø³Ù…ÛŒ'
        ].groupby('year').size().reset_index(name='Ø³ÙØ§Ø±Ø´_ØºÛŒØ±Ø±Ø³Ù…ÛŒ')
        
        stats = stats.merge(formal, left_on='Ø³Ø§Ù„', right_on='year', how='left')
        stats = stats.merge(informal, left_on='Ø³Ø§Ù„', right_on='year', how='left')
        stats = stats.drop(columns=['year_x', 'year_y'], errors='ignore')
        
        stats['Ø³ÙØ§Ø±Ø´_Ø±Ø³Ù…ÛŒ'] = stats['Ø³ÙØ§Ø±Ø´_Ø±Ø³Ù…ÛŒ'].fillna(0).astype(int)
        stats['Ø³ÙØ§Ø±Ø´_ØºÛŒØ±Ø±Ø³Ù…ÛŒ'] = stats['Ø³ÙØ§Ø±Ø´_ØºÛŒØ±Ø±Ø³Ù…ÛŒ'].fillna(0).astype(int)
        
        return stats.sort_values('Ø³Ø§Ù„')
    
    def get_monthly_stats(self, year: int = None) -> pd.DataFrame:
        """Ø¢Ù…Ø§Ø± Ù…Ø§Ù‡Ø§Ù†Ù‡"""
        if self.processed_data is None:
            return pd.DataFrame()
        
        df = self.processed_data.copy()
        
        if year:
            df = df[df['year'] == year]
        
        stats = df.groupby(['year', 'month']).agg({
            'customer_name': 'nunique',
            'mobile': 'count'
        }).reset_index()
        
        stats.columns = ['Ø³Ø§Ù„', 'Ù…Ø§Ù‡', 'ØªØ¹Ø¯Ø§Ø¯_Ù…Ø´ØªØ±ÛŒ', 'ØªØ¹Ø¯Ø§Ø¯_Ø³ÙØ§Ø±Ø´']
        
        formal = df[df['state_normalized'] == 'Ø±Ø³Ù…ÛŒ'].groupby(['year', 'month']).size()
        informal = df[df['state_normalized'] == 'ØºÛŒØ±Ø±Ø³Ù…ÛŒ'].groupby(['year', 'month']).size()
        
        stats['Ø³ÙØ§Ø±Ø´_Ø±Ø³Ù…ÛŒ'] = stats.apply(
            lambda row: formal.get((row['Ø³Ø§Ù„'], row['Ù…Ø§Ù‡']), 0), axis=1
        )
        stats['Ø³ÙØ§Ø±Ø´_ØºÛŒØ±Ø±Ø³Ù…ÛŒ'] = stats.apply(
            lambda row: informal.get((row['Ø³Ø§Ù„'], row['Ù…Ø§Ù‡']), 0), axis=1
        )
        
        return stats.sort_values(['Ø³Ø§Ù„', 'Ù…Ø§Ù‡'])
    
    def get_yearly_monthly_grouped(self) -> Dict[int, pd.DataFrame]:
        """Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø§Ù‡â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø§Ù„"""
        if self.processed_data is None:
            return {}
        
        years = sorted(self.processed_data['year'].dropna().unique())
        result = {}
        
        for year in years:
            year_int = int(year)
            monthly_data = self.get_monthly_stats(year_int)
            result[year_int] = monthly_data
        
        return result
    
    def get_product_stats(self) -> pd.DataFrame:
        """Ø¢Ù…Ø§Ø± Ù…Ø­ØµÙˆÙ„Ø§Øª (Ø¨Ø§ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ)"""
        if self.processed_data is None:
            return pd.DataFrame()
        
        # Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù†Ø±Ù…Ø§Ù„ Ø´Ø¯Ù‡ Ùˆ Ù†Ø§Ù… Ø§ØµÙ„ÛŒâ€ŒØ´Ø§Ù†
        product_mapping = {}
        
        for idx, row in self.processed_data.iterrows():
            original_products = row['products_list']
            normalized_products = row['products_list_normalized']
            
            for orig, norm in zip(original_products, normalized_products):
                if norm and norm not in product_mapping:
                    product_mapping[norm] = orig
        
        # Ø´Ù…Ø§Ø±Ø´ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù†Ø±Ù…Ø§Ù„ Ø´Ø¯Ù‡
        all_normalized_products = []
        for products_list in self.processed_data['products_list_normalized']:
            all_normalized_products.extend(products_list)
        
        all_normalized_products = [p for p in all_normalized_products if p]
        
        if not all_normalized_products:
            return pd.DataFrame(columns=['Ù…Ø­ØµÙˆÙ„', 'ØªØ¹Ø¯Ø§Ø¯_ÙØ±ÙˆØ´'])
        
        product_counts = pd.Series(all_normalized_products).value_counts().reset_index()
        product_counts.columns = ['Ù…Ø­ØµÙˆÙ„_Ù†Ø±Ù…Ø§Ù„', 'ØªØ¹Ø¯Ø§Ø¯_ÙØ±ÙˆØ´']
        
        product_counts['Ù…Ø­ØµÙˆÙ„'] = product_counts['Ù…Ø­ØµÙˆÙ„_Ù†Ø±Ù…Ø§Ù„'].map(product_mapping)
        
        product_counts = product_counts[['Ù…Ø­ØµÙˆÙ„', 'ØªØ¹Ø¯Ø§Ø¯_ÙØ±ÙˆØ´']].sort_values('ØªØ¹Ø¯Ø§Ø¯_ÙØ±ÙˆØ´', ascending=False)
        
        return product_counts
    
    def get_order_state_stats(self) -> pd.DataFrame:
        """Ø¢Ù…Ø§Ø± ÙˆØ¶Ø¹ÛŒØª Ø³ÙØ§Ø±Ø´Ø§Øª"""
        if self.processed_data is None:
            return pd.DataFrame()
        
        stats = self.processed_data.groupby('state_normalized').agg({
            'customer_name': 'nunique',
            'mobile': 'count',
            'product_count': 'sum'
        }).reset_index()
        
        stats.columns = ['ÙˆØ¶Ø¹ÛŒØª', 'ØªØ¹Ø¯Ø§Ø¯_Ù…Ø´ØªØ±ÛŒ', 'ØªØ¹Ø¯Ø§Ø¯_Ø³ÙØ§Ø±Ø´', 'ØªØ¹Ø¯Ø§Ø¯_Ù…Ø­ØµÙˆÙ„']
        
        return stats
    
    def get_customer_details(self, customer_name: str) -> pd.DataFrame:
        """Ø¬Ø²Ø¦ÛŒØ§Øª Ú©Ø§Ù…Ù„ ÛŒÚ© Ù…Ø´ØªØ±ÛŒ"""
        if self.processed_data is None:
            return pd.DataFrame()
        
        return self.processed_data[
            self.processed_data['customer_name'] == customer_name
        ].copy()
    
    # ==================== Ù…Ø´ØªØ±ÛŒØ§Ù† Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡ ====================
    
    def find_lost_customers(
        self,
        active_period_start: int = 1393,
        active_period_end: int = 1402,
        silent_period_start: int = 1403,
        silent_period_end: int = 1404,
        min_keyword_match: int = 2,
        similarity_threshold: float = 85.0,
        min_purchase_count: int = 1
    ) -> pd.DataFrame:
        """Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡"""
        if self.processed_data is None:
            raise Exception("Ø§Ø¨ØªØ¯Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ù†ÛŒØ¯.")
        
        active_customers = self.processed_data[
            (self.processed_data['year'] >= active_period_start) &
            (self.processed_data['year'] <= active_period_end)
        ].copy()
        
        recent_customers = self.processed_data[
            (self.processed_data['year'] >= silent_period_start) &
            (self.processed_data['year'] <= silent_period_end)
        ].copy()
        
        # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¯ÙˆØ±Ù‡ ÙØ¹Ø§Ù„ÛŒØª
        active_groups = []
        
        for customer_name, group in active_customers.groupby('customer_name'):
            last_year = group['year'].max()
            last_month_series = group['month'].dropna()
            last_month = int(last_month_series.iloc[-1]) if len(last_month_series) > 0 else 0
            
            mobiles = ', '.join(set(filter(None, group['mobile'].unique())))
            phones = ', '.join(set(filter(None, group['phone'].unique())))
            address = group['address'].iloc[-1] if len(group) > 0 else ''
            
            all_products = []
            for products_list in group['products_list']:
                all_products.extend(products_list)
            all_products = list(set(all_products))
            
            formal_count = len(group[group['state_normalized'] == 'Ø±Ø³Ù…ÛŒ'])
            informal_count = len(group[group['state_normalized'] == 'ØºÛŒØ±Ø±Ø³Ù…ÛŒ'])
            order_stats = f"Ø±Ø³Ù…ÛŒ: {formal_count}, ØºÛŒØ±Ø±Ø³Ù…ÛŒ: {informal_count}"
            
            active_groups.append({
                'customer_name': customer_name,
                'last_year': int(last_year) if pd.notna(last_year) else 0,
                'last_month': last_month,
                'total_purchases': len(group),
                'mobiles': mobiles,
                'phones': phones,
                'address': address,
                'products': all_products,
                'order_stats': order_stats
            })
        
        active_unique = pd.DataFrame(active_groups)
        
        if len(active_unique) == 0:
            return pd.DataFrame(columns=[
                'Ù†Ø§Ù…_Ù…Ø´ØªØ±ÛŒ', 'Ø¢Ø®Ø±ÛŒÙ†_Ø³Ø§Ù„', 'Ø¢Ø®Ø±ÛŒÙ†_Ù…Ø§Ù‡', 'ØªØ¹Ø¯Ø§Ø¯_Ø®Ø±ÛŒØ¯',
                'Ù…ÙˆØ¨Ø§ÛŒÙ„', 'ØªÙ„ÙÙ†', 'Ø¢Ø¯Ø±Ø³', 'Ù…Ø­ØµÙˆÙ„Ø§Øª', 'Ø¢Ù…Ø§Ø±_Ø³ÙØ§Ø±Ø´Ø§Øª', 'Ø§ÙˆÙ„ÙˆÛŒØª'
            ])
        
        active_unique = active_unique[active_unique['total_purchases'] >= min_purchase_count]
        
        recent_names = recent_customers['customer_name'].unique()
        
        lost_customers = []
        
        for _, row in active_unique.iterrows():
            old_name = row['customer_name']
            old_keywords = self._extract_keywords(old_name)
            
            is_found = False
            
            for new_name in recent_names:
                new_keywords = self._extract_keywords(new_name)
                
                match_score = self._calculate_keyword_match(
                    old_keywords, 
                    new_keywords, 
                    similarity_threshold
                )
                
                if match_score >= min_keyword_match:
                    is_found = True
                    break
            
            if not is_found:
                lost_customers.append(row)
        
        if not lost_customers:
            return pd.DataFrame(columns=[
                'Ù†Ø§Ù…_Ù…Ø´ØªØ±ÛŒ', 'Ø¢Ø®Ø±ÛŒÙ†_Ø³Ø§Ù„', 'Ø¢Ø®Ø±ÛŒÙ†_Ù…Ø§Ù‡', 'ØªØ¹Ø¯Ø§Ø¯_Ø®Ø±ÛŒØ¯',
                'Ù…ÙˆØ¨Ø§ÛŒÙ„', 'ØªÙ„ÙÙ†', 'Ø¢Ø¯Ø±Ø³', 'Ù…Ø­ØµÙˆÙ„Ø§Øª', 'Ø¢Ù…Ø§Ø±_Ø³ÙØ§Ø±Ø´Ø§Øª', 'Ø§ÙˆÙ„ÙˆÛŒØª'
            ])
        
        result_df = pd.DataFrame(lost_customers)
        result_df = result_df[[
            'customer_name', 'last_year', 'last_month', 'total_purchases',
            'mobiles', 'phones', 'address', 'products', 'order_stats'
        ]]
        
        result_df.columns = [
            'Ù†Ø§Ù…_Ù…Ø´ØªØ±ÛŒ', 'Ø¢Ø®Ø±ÛŒÙ†_Ø³Ø§Ù„', 'Ø¢Ø®Ø±ÛŒÙ†_Ù…Ø§Ù‡', 'ØªØ¹Ø¯Ø§Ø¯_Ø®Ø±ÛŒØ¯',
            'Ù…ÙˆØ¨Ø§ÛŒÙ„', 'ØªÙ„ÙÙ†', 'Ø¢Ø¯Ø±Ø³', 'Ù…Ø­ØµÙˆÙ„Ø§Øª', 'Ø¢Ù…Ø§Ø±_Ø³ÙØ§Ø±Ø´Ø§Øª'
        ]
        
        result_df = result_df.sort_values('ØªØ¹Ø¯Ø§Ø¯_Ø®Ø±ÛŒØ¯', ascending=False).reset_index(drop=True)
        
        result_df['Ø§ÙˆÙ„ÙˆÛŒØª'] = result_df.apply(self._calculate_priority, axis=1)
        
        result_df['Ù…Ø­ØµÙˆÙ„Ø§Øª'] = result_df['Ù…Ø­ØµÙˆÙ„Ø§Øª'].apply(
            lambda x: ', '.join(x[:5]) + ('...' if len(x) > 5 else '') if isinstance(x, list) else str(x)
        )
        
        return result_df
    
    def _extract_keywords(self, name: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø§Ø² Ù†Ø§Ù… (Ø¨Ø§ Ø­Ø°Ù Ú©Ù„Ù…Ø§Øª Ù¾Ø±ØªÚ©Ø±Ø§Ø±)"""
        stopwords = {
            'Ø´Ø±Ú©Øª', 'Ù…ÙˆØ³Ø³Ù‡', 'Ú¯Ø±ÙˆÙ‡', 'Ø³Ø§Ø²Ù…Ø§Ù†', 'Ù…Ø¬Ù…ÙˆØ¹Ù‡',
            'Ù…Ù‡Ù†Ø¯Ø³ÛŒ', 'Ù¾ÛŒÙ…Ø§Ù†Ú©Ø§Ø±ÛŒ', 'Ø³Ø§Ø®ØªÙ…Ø§Ù†ÛŒ', 'Ø¹Ù…Ø±Ø§Ù†ÛŒ',
            'ØªØ¬Ø§Ø±ÛŒ', 'ØµÙ†Ø¹ØªÛŒ', 'Ø®Ø¯Ù…Ø§ØªÛŒ', 'ÙÙ†ÛŒ', 'ØªÙˆÙ„ÛŒØ¯ÛŒ',
            'Ø¨Ø§Ø²Ø±Ú¯Ø§Ù†ÛŒ', 'Ù¾Ø±ÙˆÚ˜Ù‡', 'Ø³Ù‡Ø§Ù…ÛŒ', 'Ø®Ø§Øµ', 'Ø¹Ø§Ù…',
            'Ù…Ø­Ø¯ÙˆØ¯', 'Ùˆ', 'Ø¯Ø±', 'Ø¨Ù‡', 'Ø§Ø²', 'Ø¨Ø§'
        }
        
        normalized = self._normalize_text(name)
        words = normalized.split()
        keywords = [word for word in words if word not in stopwords and len(word) > 2]
        
        return keywords
    
    def _calculate_keyword_match(
        self, 
        keywords1: List[str], 
        keywords2: List[str],
        threshold: float = 85.0
    ) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ù…Ø´ØªØ±Ú© ÛŒØ§ Ø´Ø¨ÛŒÙ‡"""
        match_count = 0.0
        used_keywords2 = set()
        
        for kw1 in keywords1:
            best_match = 0.0
            best_kw2 = None
            
            for kw2 in keywords2:
                if kw2 in used_keywords2:
                    continue
                
                if kw1 == kw2:
                    best_match = 1.0
                    best_kw2 = kw2
                    break
                
                similarity = fuzz.ratio(kw1, kw2)
                if similarity >= threshold and similarity > best_match * 100:
                    best_match = similarity / 100.0
                    best_kw2 = kw2
            
            if best_kw2:
                match_count += best_match
                used_keywords2.add(best_kw2)
        
        return match_count
    
    def _calculate_priority(self, row) -> str:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§ÙˆÙ„ÙˆÛŒØª Ù…Ø´ØªØ±ÛŒ"""
        purchases = row['ØªØ¹Ø¯Ø§Ø¯_Ø®Ø±ÛŒØ¯']
        last_year = row['Ø¢Ø®Ø±ÛŒÙ†_Ø³Ø§Ù„']
        
        if purchases >= 10 and last_year >= 1402:
            return 'ğŸ”´ Ø¨Ø§Ù„Ø§'
        elif purchases >= 5 and last_year >= 1401:
            return 'ğŸŸ¡ Ù…ØªÙˆØ³Ø·'
        else:
            return 'ğŸŸ¢ Ù¾Ø§ÛŒÛŒÙ†'
    
    def export_lost_customers_to_excel(
        self, 
        lost_df: pd.DataFrame, 
        filename: str = None
    ) -> str:
        """Ø®Ø±ÙˆØ¬ÛŒ Ø§Ú©Ø³Ù„ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡"""
        if filename is None:
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"lost_customers_{timestamp}.xlsx"
        
        output_dir = Path("exports")
        output_dir.mkdir(exist_ok=True)
        
        filepath = output_dir / filename
        
        with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
            lost_df.to_excel(writer, sheet_name='Ù…Ø´ØªØ±ÛŒØ§Ù† Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡', index=False)
            
            stats_data = {
                'Ø´Ø§Ø®Øµ': [
                    'ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡',
                    'Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¨Ø§ Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§Ù„Ø§',
                    'Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¨Ø§ Ø§ÙˆÙ„ÙˆÛŒØª Ù…ØªÙˆØ³Ø·',
                    'Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¨Ø§ Ø§ÙˆÙ„ÙˆÛŒØª Ù¾Ø§ÛŒÛŒÙ†',
                    'Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ØªØ¹Ø¯Ø§Ø¯ Ø®Ø±ÛŒØ¯',
                    'Ù…Ø¬Ù…ÙˆØ¹ Ø®Ø±ÛŒØ¯Ù‡Ø§ÛŒ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡'
                ],
                'Ù…Ù‚Ø¯Ø§Ø±': [
                    len(lost_df),
                    len(lost_df[lost_df['Ø§ÙˆÙ„ÙˆÛŒØª'] == 'ğŸ”´ Ø¨Ø§Ù„Ø§']),
                    len(lost_df[lost_df['Ø§ÙˆÙ„ÙˆÛŒØª'] == 'ğŸŸ¡ Ù…ØªÙˆØ³Ø·']),
                    len(lost_df[lost_df['Ø§ÙˆÙ„ÙˆÛŒØª'] == 'ğŸŸ¢ Ù¾Ø§ÛŒÛŒÙ†']),
                    round(lost_df['ØªØ¹Ø¯Ø§Ø¯_Ø®Ø±ÛŒØ¯'].mean(), 2) if len(lost_df) > 0 else 0,
                    lost_df['ØªØ¹Ø¯Ø§Ø¯_Ø®Ø±ÛŒØ¯'].sum()
                ]
            }
            
            stats_df = pd.DataFrame(stats_data)
            stats_df.to_excel(writer, sheet_name='Ø¢Ù…Ø§Ø±', index=False)
            
            workbook = writer.book
            worksheet = writer.sheets['Ù…Ø´ØªØ±ÛŒØ§Ù† Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ‡']
            
            worksheet.column_dimensions['A'].width = 35
            worksheet.column_dimensions['B'].width = 12
            worksheet.column_dimensions['C'].width = 12
            worksheet.column_dimensions['D'].width = 15
            worksheet.column_dimensions['E'].width = 25
            worksheet.column_dimensions['F'].width = 25
            worksheet.column_dimensions['G'].width = 50
            worksheet.column_dimensions['H'].width = 50
            worksheet.column_dimensions['I'].width = 30
            worksheet.column_dimensions['J'].width = 15
        
        return str(filepath)
    
    # ==================== CRM ====================
    
    def add_customer(
        self,
        customer_name: str,
        year: int,
        month: int,
        state: str,
        address: str,
        mobile: str,
        phone: str,
        products: str
    ) -> bool:
        """Ø§ÙØ²ÙˆØ¯Ù† Ø³ÙØ§Ø±Ø´ Ø¬Ø¯ÛŒØ¯"""
        try:
            new_row = {
                'customer name': customer_name,
                'year': year,
                'month': month,
                'state': state,
                'address': address,
                'Ø´Ù…Ø§Ø±Ù‡ Ù…ÙˆØ¨Ø§ÛŒÙ„': mobile,
                'Ø´Ù…Ø§Ø±Ù‡ Ø«Ø§Ø¨Øª': phone,
                'Ù†Ø§Ù… Ù…Ø­ØµÙˆÙ„': products,
                'sheet_name': f'Added_{datetime.datetime.now().strftime("%Y%m%d")}'
            }
            
            self.df = pd.concat([self.df, pd.DataFrame([new_row])], ignore_index=True)
            self.process_data()
            self.save_to_excel()
            
            return True
            
        except Exception as e:
            print(f"Ø®Ø·Ø§: {e}")
            return False
    
    def update_customer(
        self,
        index: int,
        customer_name: str = None,
        year: int = None,
        month: int = None,
        state: str = None,
        address: str = None,
        mobile: str = None,
        phone: str = None,
        products: str = None
    ) -> bool:
        """ÙˆÛŒØ±Ø§ÛŒØ´ Ø³ÙØ§Ø±Ø´"""
        try:
            if customer_name:
                self.df.at[index, 'customer name'] = customer_name
            if year:
                self.df.at[index, 'year'] = year
            if month:
                self.df.at[index, 'month'] = month
            if state:
                self.df.at[index, 'state'] = state
            if address:
                self.df.at[index, 'address'] = address
            if mobile:
                self.df.at[index, 'Ø´Ù…Ø§Ø±Ù‡ Ù…ÙˆØ¨Ø§ÛŒÙ„'] = mobile
            if phone:
                self.df.at[index, 'Ø´Ù…Ø§Ø±Ù‡ Ø«Ø§Ø¨Øª'] = phone
            if products:
                self.df.at[index, 'Ù†Ø§Ù… Ù…Ø­ØµÙˆÙ„'] = products
            
            self.process_data()
            self.save_to_excel()
            
            return True
            
        except Exception as e:
            print(f"Ø®Ø·Ø§: {e}")
            return False
    
    def delete_customer(self, index: int) -> bool:
        """Ø­Ø°Ù Ø³ÙØ§Ø±Ø´"""
        try:
            self.df = self.df.drop(index).reset_index(drop=True)
            self.process_data()
            self.save_to_excel()
            return True
        except Exception as e:
            print(f"Ø®Ø·Ø§: {e}")
            return False
    
    # ==================== Ø°Ø®ÛŒØ±Ù‡ ====================
    
    def save_to_excel(self, output_file: str = None):
        """Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„"""
        output_file = output_file or self.excel_file
        
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            for sheet_name in self.df['sheet_name'].unique():
                sheet_df = self.df[self.df['sheet_name'] == sheet_name]
                sheet_df = sheet_df.drop(columns=['sheet_name'])
                sheet_df.to_excel(writer, sheet_name=str(sheet_name), index=False)
    
    def export_to_excel(self, filename: str, data: pd.DataFrame):
        """Ø®Ø±ÙˆØ¬ÛŒ Ø§Ú©Ø³Ù„"""
        data.to_excel(filename, index=False, engine='openpyxl')